{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1.webp, Tags: ['clothes']\n",
      "Image: 2.webp, Tags: ['shoe']\n",
      "Generated tags for all images in the folder: {'1.webp': ['clothes'], '2.webp': ['shoe']}\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load CLIP model and preprocess function\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Step 1: Define a Broad Set of Potential Tags (Expand as needed)\n",
    "# This set could include general categories, common objects, etc.\n",
    "potential_tags = [\n",
    "    \"person\", \"woman\", \"man\", \"child\", \"dog\", \"cat\", \"sofa\", \"car\", \"tree\", \"sky\",\n",
    "    \"flower\", \"shoe\", \"bag\", \"laptop\", \"phone\", \"house\", \"building\", \"animal\",\n",
    "    \"beach\", \"mountain\", \"river\", \"food\", \"fruit\", \"book\", \"desk\", \"chair\", \"lamp\",\n",
    "    \"bottle\", \"keyboard\", \"plant\", \"bird\", \"sunset\", \"rain\", \"street\", \"bicycle\",\n",
    "    \"clouds\", \"sand\", \"road\", \"city\", \"forest\", \"water\", \"painting\", \"camera\",\n",
    "    \"clothes\", \"glasses\", \"accessories\", \"hat\", \"vehicle\", \"computer\"\n",
    "]  # Add more general tags as needed\n",
    "\n",
    "# Step 2: Function to Dynamically Generate Tags for Each Image in a Folder\n",
    "def generate_dynamic_tags(image_folder):\n",
    "    tags_dict = {}\n",
    "    for img_file in os.listdir(image_folder):\n",
    "        if img_file.lower().endswith(('jpg', 'jpeg', 'png', 'webp')):  # Ensure only images are processed\n",
    "            image_path = os.path.join(image_folder, img_file)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "            # Encode image using CLIP\n",
    "            with torch.no_grad():\n",
    "                text_inputs = clip.tokenize(potential_tags).to(device)\n",
    "                logits_per_image, _ = model(image_tensor, text_inputs)\n",
    "                probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            # Filter tags based on a probability threshold\n",
    "            threshold = 0.2  # Adjust threshold as needed to be more/less selective\n",
    "            selected_tags = [potential_tags[i] for i, prob in enumerate(probs[0]) if prob > threshold]\n",
    "            \n",
    "            # Add the generated tags to the dictionary for each image\n",
    "            tags_dict[img_file] = selected_tags\n",
    "            print(f\"Image: {img_file}, Tags: {selected_tags}\")\n",
    "\n",
    "    return tags_dict\n",
    "\n",
    "# Usage: Generate tags for all images in the specified folder\n",
    "image_folder = \"D:/SNU/Semester VII/CSD358 Information Retrieval/Project/images\"\n",
    "tags_dict = generate_dynamic_tags(image_folder)\n",
    "print(\"Generated tags for all images in the folder:\", tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
